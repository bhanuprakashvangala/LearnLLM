{
  "challenges": [
    {
      "id": "1",
      "title": "Build Your First Chatbot",
      "description": "Create a simple chatbot using any LLM API (Claude, Gemini, or others) that can answer questions about a specific topic",
      "difficulty": "beginner",
      "points": 100,
      "timeEstimate": "30 min",
      "category": "API Integration",
      "skills": ["API", "Prompting", "JavaScript"],
      "prerequisites": [],
      "instructions": [
        "Choose an LLM provider (Claude API, Google Gemini, Groq, or any other)",
        "Set up your development environment with Node.js or Python",
        "Install the SDK for your chosen provider (e.g., @anthropic-ai/sdk, @google/generative-ai)",
        "Create a simple script that sends a message to the API and displays the response",
        "Add a system prompt to give your chatbot a specific personality or expertise",
        "Implement a conversation loop that allows multiple back-and-forth messages",
        "Test your chatbot with various questions to ensure it responds appropriately"
      ],
      "resources": [
        {"title": "Anthropic Claude API Docs", "url": "https://docs.anthropic.com"},
        {"title": "Google Gemini API Docs", "url": "https://ai.google.dev/docs"},
        {"title": "Groq API Docs", "url": "https://console.groq.com/docs"}
      ],
      "hints": [
        "Start with a free tier API to avoid costs while learning",
        "Use environment variables to store your API keys securely",
        "Keep your first chatbot simple - complexity can come later"
      ]
    },
    {
      "id": "2",
      "title": "Prompt Engineering Master",
      "description": "Design 5 different prompts for various tasks using advanced techniques like few-shot learning and chain of thought",
      "difficulty": "beginner",
      "points": 150,
      "timeEstimate": "45 min",
      "category": "Prompt Engineering",
      "skills": ["Prompting", "Chain of Thought", "Few-Shot"],
      "prerequisites": [],
      "instructions": [
        "Create a zero-shot prompt for text summarization",
        "Design a few-shot prompt with 3 examples for sentiment analysis",
        "Build a chain-of-thought prompt for solving math word problems",
        "Write a role-playing prompt that gives the AI a specific persona",
        "Craft a structured output prompt that returns JSON format",
        "Test each prompt with multiple inputs to verify consistency",
        "Document what makes each prompt effective"
      ],
      "resources": [
        {"title": "Prompt Engineering Guide", "url": "https://www.promptingguide.ai"},
        {"title": "Anthropic Prompt Library", "url": "https://docs.anthropic.com/claude/prompt-library"}
      ],
      "hints": [
        "Be specific and clear in your instructions",
        "Few-shot examples should be diverse and representative",
        "Chain-of-thought works best for reasoning tasks"
      ]
    },
    {
      "id": "3",
      "title": "Document Q&A System",
      "description": "Build a RAG system that can answer questions from uploaded PDF documents",
      "difficulty": "intermediate",
      "points": 250,
      "timeEstimate": "2 hours",
      "category": "RAG",
      "skills": ["RAG", "Embeddings", "Vector DB", "LangChain"],
      "prerequisites": ["1", "2"],
      "instructions": [
        "Set up a vector database (Pinecone, Chroma, or Weaviate)",
        "Create a document loader to read PDF files",
        "Split documents into smaller chunks (500-1000 tokens each)",
        "Generate embeddings for each chunk using an embedding model",
        "Store the embeddings in your vector database",
        "Implement a retrieval function that finds relevant chunks for a query",
        "Combine retrieved context with the user question to generate answers",
        "Add source citations to your responses"
      ],
      "resources": [
        {"title": "LangChain RAG Tutorial", "url": "https://python.langchain.com/docs/tutorials/rag"},
        {"title": "Pinecone Quickstart", "url": "https://docs.pinecone.io/guides/get-started/quickstart"}
      ],
      "hints": [
        "Chunk size affects retrieval quality - experiment with different sizes",
        "Use overlap between chunks to maintain context",
        "Consider using hybrid search (semantic + keyword) for better results"
      ]
    },
    {
      "id": "4",
      "title": "Custom AI Agent",
      "description": "Create an autonomous agent that can research topics and provide comprehensive summaries using tools",
      "difficulty": "intermediate",
      "points": 300,
      "timeEstimate": "3 hours",
      "category": "AI Agents",
      "skills": ["Agents", "Tools", "ReAct", "LangChain"],
      "prerequisites": ["1", "2"],
      "instructions": [
        "Define 3-5 tools your agent can use (web search, calculator, file reader, etc.)",
        "Create tool descriptions that help the LLM understand when to use each tool",
        "Implement the ReAct pattern: Reasoning, Acting, and Observing",
        "Build a loop that allows the agent to take multiple actions",
        "Add error handling for when tools fail or return unexpected results",
        "Implement a stopping condition to prevent infinite loops",
        "Test your agent with complex multi-step tasks"
      ],
      "resources": [
        {"title": "LangChain Agents", "url": "https://python.langchain.com/docs/modules/agents"},
        {"title": "ReAct Paper", "url": "https://arxiv.org/abs/2210.03629"}
      ],
      "hints": [
        "Start with simple tools before adding complex ones",
        "Clear tool descriptions are crucial for agent performance",
        "Limit the number of iterations to prevent runaway costs"
      ]
    },
    {
      "id": "5",
      "title": "Semantic Search Engine",
      "description": "Build a semantic search engine using embeddings and hybrid search techniques",
      "difficulty": "intermediate",
      "points": 350,
      "timeEstimate": "3 hours",
      "category": "Vector Search",
      "skills": ["Embeddings", "Vector DB", "BM25", "Hybrid Search"],
      "prerequisites": ["3"],
      "instructions": [
        "Set up a dataset of documents to search (articles, products, or FAQs)",
        "Implement BM25 keyword search as a baseline",
        "Generate embeddings for all documents using a sentence transformer",
        "Implement vector similarity search using cosine similarity",
        "Create a hybrid search that combines BM25 and vector scores",
        "Add a re-ranking step using a cross-encoder model",
        "Build a simple UI to test search queries",
        "Measure and compare search quality across methods"
      ],
      "resources": [
        {"title": "Sentence Transformers", "url": "https://www.sbert.net"},
        {"title": "Hybrid Search Explained", "url": "https://www.pinecone.io/learn/hybrid-search"}
      ],
      "hints": [
        "Normalize scores before combining BM25 and vector results",
        "Cross-encoder re-ranking is slow but significantly improves quality",
        "Consider using reciprocal rank fusion for combining results"
      ]
    },
    {
      "id": "6",
      "title": "Fine-tune Your Own Model",
      "description": "Fine-tune a small language model on a custom dataset using LoRA techniques",
      "difficulty": "advanced",
      "points": 500,
      "timeEstimate": "4 hours",
      "category": "Fine-tuning",
      "skills": ["LoRA", "Fine-tuning", "PyTorch", "Hugging Face"],
      "prerequisites": ["3", "4", "5"],
      "instructions": [
        "Choose a base model (Llama, Mistral, or Phi)",
        "Prepare your training dataset in the correct format (instruction/response pairs)",
        "Set up your training environment with GPU access (Colab, RunPod, or local)",
        "Configure LoRA parameters (rank, alpha, target modules)",
        "Implement the training loop using PEFT library",
        "Monitor training loss and validation metrics",
        "Merge LoRA weights with the base model",
        "Test your fine-tuned model on held-out examples"
      ],
      "resources": [
        {"title": "Hugging Face PEFT", "url": "https://huggingface.co/docs/peft"},
        {"title": "LoRA Paper", "url": "https://arxiv.org/abs/2106.09685"}
      ],
      "hints": [
        "Start with a small dataset to verify your pipeline works",
        "LoRA rank of 8-16 is usually sufficient for most tasks",
        "Use gradient checkpointing to reduce memory usage"
      ]
    },
    {
      "id": "7",
      "title": "Production RAG System",
      "description": "Deploy a production-ready RAG application with caching, monitoring, and optimization",
      "difficulty": "advanced",
      "points": 600,
      "timeEstimate": "6 hours",
      "category": "Deployment",
      "skills": ["RAG", "Production", "Monitoring", "Optimization"],
      "prerequisites": ["3", "5"],
      "instructions": [
        "Containerize your RAG application with Docker",
        "Implement query caching using Redis to reduce API costs",
        "Add request/response logging for debugging and analytics",
        "Set up monitoring with latency tracking and error rates",
        "Implement rate limiting to protect your endpoints",
        "Add authentication and API key management",
        "Optimize retrieval with query expansion and re-ranking",
        "Deploy to a cloud platform (AWS, GCP, or Vercel)"
      ],
      "resources": [
        {"title": "FastAPI Best Practices", "url": "https://fastapi.tiangolo.com/deployment"},
        {"title": "LangSmith Monitoring", "url": "https://docs.smith.langchain.com"}
      ],
      "hints": [
        "Cache both embeddings and LLM responses for maximum savings",
        "Use async processing for better throughput",
        "Implement graceful degradation when services are unavailable"
      ]
    },
    {
      "id": "8",
      "title": "Multi-Agent System",
      "description": "Build a collaborative multi-agent system where agents work together to solve complex tasks",
      "difficulty": "advanced",
      "points": 700,
      "timeEstimate": "8 hours",
      "category": "Advanced Agents",
      "skills": ["Multi-Agent", "Coordination", "Complex Tasks"],
      "prerequisites": ["4", "6"],
      "instructions": [
        "Design your agent roles (researcher, writer, critic, coordinator)",
        "Implement a message passing system between agents",
        "Create a coordinator agent that delegates tasks",
        "Build individual agents with specialized capabilities",
        "Implement a shared memory or context system",
        "Add conflict resolution when agents disagree",
        "Create a workflow for agents to review each other's work",
        "Test the system on a complex task requiring collaboration"
      ],
      "resources": [
        {"title": "AutoGen Framework", "url": "https://microsoft.github.io/autogen"},
        {"title": "CrewAI Docs", "url": "https://docs.crewai.com"}
      ],
      "hints": [
        "Start with 2-3 agents before scaling up",
        "Clear role definitions prevent agent confusion",
        "Limit communication rounds to control costs and latency"
      ]
    },
    {
      "id": "9",
      "title": "Text Classification Pipeline",
      "description": "Build an AI that categorizes text into predefined categories with confidence scores",
      "difficulty": "beginner",
      "points": 120,
      "timeEstimate": "30 min",
      "category": "Classification",
      "skills": ["Classification", "Prompting", "JSON Output"],
      "prerequisites": ["1"],
      "instructions": [
        "Define 5-10 categories for classification",
        "Create a prompt that explains the categories",
        "Request structured JSON output with category and confidence",
        "Test with diverse examples",
        "Handle edge cases and ambiguous inputs"
      ],
      "resources": [
        {"title": "Text Classification Guide", "url": "https://www.promptingguide.ai/applications/classification"}
      ],
      "hints": [
        "Clear category definitions improve accuracy",
        "Include examples for each category in your prompt",
        "Ask for confidence scores to handle uncertainty"
      ]
    },
    {
      "id": "10",
      "title": "Language Translation Bot",
      "description": "Create a multi-language translator that preserves tone and context",
      "difficulty": "beginner",
      "points": 130,
      "timeEstimate": "35 min",
      "category": "NLP",
      "skills": ["Translation", "Prompting", "Multi-language"],
      "prerequisites": ["1"],
      "instructions": [
        "Support translation between 5+ languages",
        "Preserve the original tone (formal, casual, etc.)",
        "Handle idioms and cultural expressions",
        "Provide alternative translations when appropriate",
        "Detect the source language automatically"
      ],
      "resources": [
        {"title": "LLM Translation Best Practices", "url": "https://docs.anthropic.com"}
      ],
      "hints": [
        "Ask the AI to explain idioms rather than literal translation",
        "Include context about the text's purpose",
        "Request multiple translation options for ambiguous phrases"
      ]
    },
    {
      "id": "11",
      "title": "Conversation Memory System",
      "description": "Build a chatbot that remembers context across multiple messages",
      "difficulty": "intermediate",
      "points": 200,
      "timeEstimate": "1 hour",
      "category": "Memory",
      "skills": ["Context Management", "Memory", "Conversation"],
      "prerequisites": ["1", "2"],
      "instructions": [
        "Implement a message history array",
        "Add context window management for long conversations",
        "Create a summary system for older messages",
        "Track key facts mentioned in the conversation",
        "Handle context overflow gracefully"
      ],
      "resources": [
        {"title": "Conversation Memory Patterns", "url": "https://python.langchain.com/docs/modules/memory"}
      ],
      "hints": [
        "Store both user and assistant messages",
        "Summarize old messages to save tokens",
        "Extract and store key facts separately"
      ]
    },
    {
      "id": "12",
      "title": "AI Content Moderator",
      "description": "Create an AI system that detects and flags inappropriate content",
      "difficulty": "intermediate",
      "points": 220,
      "timeEstimate": "1 hour",
      "category": "Safety",
      "skills": ["Content Moderation", "Classification", "Safety"],
      "prerequisites": ["2", "9"],
      "instructions": [
        "Define content categories (spam, hate speech, NSFW, etc.)",
        "Create a multi-label classification system",
        "Implement severity scoring (low, medium, high)",
        "Handle context-dependent cases",
        "Provide explanations for flagged content"
      ],
      "resources": [
        {"title": "AI Safety Guidelines", "url": "https://docs.anthropic.com/claude/docs/content-moderation"}
      ],
      "hints": [
        "Consider context - some words are only harmful in certain contexts",
        "Provide clear reasoning for moderation decisions",
        "Balance false positives and false negatives"
      ]
    },
    {
      "id": "13",
      "title": "Data Extraction Pipeline",
      "description": "Extract structured data from unstructured text like emails, invoices, or articles",
      "difficulty": "intermediate",
      "points": 280,
      "timeEstimate": "2 hours",
      "category": "Data Extraction",
      "skills": ["Entity Extraction", "NER", "JSON Output"],
      "prerequisites": ["2", "5"],
      "instructions": [
        "Define the data schema you want to extract",
        "Create extraction prompts for different document types",
        "Handle missing or uncertain information",
        "Validate extracted data",
        "Support multiple output formats"
      ],
      "resources": [
        {"title": "Structured Data Extraction", "url": "https://www.promptingguide.ai/applications/structured_outputs"}
      ],
      "hints": [
        "Be very specific about the output schema",
        "Ask the AI to say 'unknown' for missing information",
        "Include validation logic for extracted data"
      ]
    },
    {
      "id": "14",
      "title": "AI Writing Assistant",
      "description": "Build a comprehensive writing assistant that helps with drafts, editing, and style",
      "difficulty": "intermediate",
      "points": 320,
      "timeEstimate": "2.5 hours",
      "category": "Writing",
      "skills": ["Writing", "Editing", "Style Analysis"],
      "prerequisites": ["2", "6"],
      "instructions": [
        "Implement grammar and spelling correction",
        "Create tone analysis and adjustment features",
        "Add style suggestions based on context",
        "Support multiple writing formats (email, blog, report)",
        "Provide readability scoring"
      ],
      "resources": [
        {"title": "Writing with AI", "url": "https://www.promptingguide.ai/applications/writing"}
      ],
      "hints": [
        "Different writing contexts need different styles",
        "Show tracked changes for editing suggestions",
        "Explain why changes improve the writing"
      ]
    },
    {
      "id": "15",
      "title": "AI Workflow Automation",
      "description": "Chain multiple AI tasks together to automate complex workflows",
      "difficulty": "advanced",
      "points": 550,
      "timeEstimate": "5 hours",
      "category": "Automation",
      "skills": ["Workflow", "Chaining", "Automation"],
      "prerequisites": ["4", "7"],
      "instructions": [
        "Design a multi-step workflow with 3+ stages",
        "Implement data passing between stages",
        "Add conditional logic based on AI outputs",
        "Handle errors and retries gracefully",
        "Monitor workflow progress and status"
      ],
      "resources": [
        {"title": "LangChain Chains", "url": "https://python.langchain.com/docs/modules/chains"}
      ],
      "hints": [
        "Break complex tasks into simple, focused steps",
        "Validate outputs before passing to next stage",
        "Log each step for debugging"
      ]
    }
  ]
}
